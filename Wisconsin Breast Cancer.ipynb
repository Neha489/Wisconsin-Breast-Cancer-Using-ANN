{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "979b6865",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.layers import Dense, Input\n",
    "from keras import Sequential\n",
    "from keras.losses import MeanSquaredError, BinaryCrossentropy\n",
    "from keras.activations import sigmoid\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67b3ba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset\n",
    "df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ec27d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302         M        17.99         10.38          122.80     1001.0   \n",
       "1      842517         M        20.57         17.77          132.90     1326.0   \n",
       "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3    84348301         M        11.42         20.38           77.58      386.1   \n",
       "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
       "..        ...       ...          ...           ...             ...        ...   \n",
       "564    926424         M        21.56         22.39          142.00     1479.0   \n",
       "565    926682         M        20.13         28.25          131.20     1261.0   \n",
       "566    926954         M        16.60         28.08          108.30      858.1   \n",
       "567    927241         M        20.60         29.33          140.10     1265.0   \n",
       "568     92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0    ...          17.33           184.60      2019.0           0.16220   \n",
       "1    ...          23.41           158.80      1956.0           0.12380   \n",
       "2    ...          25.53           152.50      1709.0           0.14440   \n",
       "3    ...          26.50            98.87       567.7           0.20980   \n",
       "4    ...          16.67           152.20      1575.0           0.13740   \n",
       "..   ...            ...              ...         ...               ...   \n",
       "564  ...          26.40           166.10      2027.0           0.14100   \n",
       "565  ...          38.25           155.00      1731.0           0.11660   \n",
       "566  ...          34.12           126.70      1124.0           0.11390   \n",
       "567  ...          39.42           184.60      1821.0           0.16500   \n",
       "568  ...          30.37            59.16       268.6           0.08996   \n",
       "\n",
       "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0              0.66560           0.7119                0.2654          0.4601   \n",
       "1              0.18660           0.2416                0.1860          0.2750   \n",
       "2              0.42450           0.4504                0.2430          0.3613   \n",
       "3              0.86630           0.6869                0.2575          0.6638   \n",
       "4              0.20500           0.4000                0.1625          0.2364   \n",
       "..                 ...              ...                   ...             ...   \n",
       "564            0.21130           0.4107                0.2216          0.2060   \n",
       "565            0.19220           0.3215                0.1628          0.2572   \n",
       "566            0.30940           0.3403                0.1418          0.2218   \n",
       "567            0.86810           0.9387                0.2650          0.4087   \n",
       "568            0.06444           0.0000                0.0000          0.2871   \n",
       "\n",
       "     fractal_dimension_worst  Unnamed: 32  \n",
       "0                    0.11890          NaN  \n",
       "1                    0.08902          NaN  \n",
       "2                    0.08758          NaN  \n",
       "3                    0.17300          NaN  \n",
       "4                    0.07678          NaN  \n",
       "..                       ...          ...  \n",
       "564                  0.07115          NaN  \n",
       "565                  0.06637          NaN  \n",
       "566                  0.07820          NaN  \n",
       "567                  0.12400          NaN  \n",
       "568                  0.07039          NaN  \n",
       "\n",
       "[569 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baa5e91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.columns[df.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b8b0d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84a87450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                         0\n",
       "diagnosis                  0\n",
       "radius_mean                0\n",
       "texture_mean               0\n",
       "perimeter_mean             0\n",
       "area_mean                  0\n",
       "smoothness_mean            0\n",
       "compactness_mean           0\n",
       "concavity_mean             0\n",
       "concave points_mean        0\n",
       "symmetry_mean              0\n",
       "fractal_dimension_mean     0\n",
       "radius_se                  0\n",
       "texture_se                 0\n",
       "perimeter_se               0\n",
       "area_se                    0\n",
       "smoothness_se              0\n",
       "compactness_se             0\n",
       "concavity_se               0\n",
       "concave points_se          0\n",
       "symmetry_se                0\n",
       "fractal_dimension_se       0\n",
       "radius_worst               0\n",
       "texture_worst              0\n",
       "perimeter_worst            0\n",
       "area_worst                 0\n",
       "smoothness_worst           0\n",
       "compactness_worst          0\n",
       "concavity_worst            0\n",
       "concave points_worst       0\n",
       "symmetry_worst             0\n",
       "fractal_dimension_worst    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cf57de",
   "metadata": {},
   "source": [
    "- There is no null value in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f781059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    357\n",
       "M    212\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27c21a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['diagnosis'].value_counts().plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4a42078",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diagnosis'] = df['diagnosis'].map({'M':1,'B':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4394098b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5c50a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.9</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0          1        17.99         10.38           122.8     1001.0   \n",
       "1          1        20.57         17.77           132.9     1326.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33            184.6   \n",
       "1         0.1812  ...         24.99          23.41            158.8   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e19e52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('diagnosis',1)\n",
    "y = df['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5103389",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "383b80c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((455, 30), (455,), (114, 30), (114,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fc1acbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X_train)\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46512de8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 9)                 279       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 9)                 90        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 379\n",
      "Trainable params: 379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initializing the ANN\n",
    "classifier = Sequential()\n",
    "#adding the input layer and first hidden layer\n",
    "classifier.add(Dense(units=9,kernel_initializer='he_uniform',activation='relu',input_dim=30))\n",
    "\n",
    "#adding the second hidden layer\n",
    "classifier.add(Dense(units=9,kernel_initializer='glorot_uniform',activation='relu'))\n",
    "\n",
    "#adding the output layer\n",
    "classifier.add(Dense(units=1,kernel_initializer='glorot_uniform',activation='sigmoid'))\n",
    "\n",
    "#compiling the ann\n",
    "classifier.compile(optimizer = 'adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ae77381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 3s 4ms/step - loss: 0.6964 - accuracy: 0.5165\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5496 - accuracy: 0.7385\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.4541 - accuracy: 0.8505\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.3862 - accuracy: 0.8769\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.8989\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.2891 - accuracy: 0.9165\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.2522 - accuracy: 0.9407\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.2220 - accuracy: 0.9495\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1966 - accuracy: 0.9516\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1752 - accuracy: 0.9582\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1577 - accuracy: 0.9648\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1441 - accuracy: 0.9670\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1321 - accuracy: 0.9692\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.1226 - accuracy: 0.9736\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.1147 - accuracy: 0.9758\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1080 - accuracy: 0.9758\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.1025 - accuracy: 0.9758\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0975 - accuracy: 0.9758\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0932 - accuracy: 0.9758\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0897 - accuracy: 0.9758\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0864 - accuracy: 0.9758\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0837 - accuracy: 0.9758\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0814 - accuracy: 0.9780\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0786 - accuracy: 0.9802\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0766 - accuracy: 0.9824\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0749 - accuracy: 0.9824\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0730 - accuracy: 0.9824\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0716 - accuracy: 0.9824\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0703 - accuracy: 0.9824\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0690 - accuracy: 0.9824\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0677 - accuracy: 0.9824\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0669 - accuracy: 0.9846\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0657 - accuracy: 0.9846\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0645 - accuracy: 0.9846\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0638 - accuracy: 0.9846\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0628 - accuracy: 0.9846\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0624 - accuracy: 0.9846\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0609 - accuracy: 0.9846\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0600 - accuracy: 0.9868\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0591 - accuracy: 0.9868\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0583 - accuracy: 0.9868\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0576 - accuracy: 0.9868\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0567 - accuracy: 0.9890\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0558 - accuracy: 0.9890\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0551 - accuracy: 0.9890\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0545 - accuracy: 0.9890\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0538 - accuracy: 0.9912\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0530 - accuracy: 0.9912\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0523 - accuracy: 0.9912\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 0.0516 - accuracy: 0.9912\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0511 - accuracy: 0.9912\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0502 - accuracy: 0.9912\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0497 - accuracy: 0.9912\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.0490 - accuracy: 0.9912\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 0.0488 - accuracy: 0.9912\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.0478 - accuracy: 0.9912\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0475 - accuracy: 0.9912\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0464 - accuracy: 0.9912\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0459 - accuracy: 0.9912\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0453 - accuracy: 0.9912\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0447 - accuracy: 0.9912\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0441 - accuracy: 0.9912\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0435 - accuracy: 0.9912\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0430 - accuracy: 0.9912\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0423 - accuracy: 0.9912\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0419 - accuracy: 0.9912\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.9912\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0410 - accuracy: 0.9912\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0402 - accuracy: 0.9912\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0396 - accuracy: 0.9912\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0391 - accuracy: 0.9934\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0386 - accuracy: 0.9934\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0381 - accuracy: 0.9934\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0377 - accuracy: 0.9934\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0373 - accuracy: 0.9934\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0366 - accuracy: 0.9934\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0360 - accuracy: 0.9934\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0355 - accuracy: 0.9934\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0349 - accuracy: 0.9934\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0345 - accuracy: 0.9934\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0342 - accuracy: 0.9934\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0336 - accuracy: 0.9934\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0332 - accuracy: 0.9934\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0328 - accuracy: 0.9934\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0321 - accuracy: 0.9934\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0320 - accuracy: 0.9934\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0321 - accuracy: 0.9934\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0316 - accuracy: 0.9934\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0309 - accuracy: 0.9934\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0303 - accuracy: 0.9934\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0299 - accuracy: 0.9934\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0295 - accuracy: 0.9934\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0292 - accuracy: 0.9934\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0288 - accuracy: 0.9934\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0284 - accuracy: 0.9934\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0279 - accuracy: 0.9934\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0275 - accuracy: 0.9934\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0272 - accuracy: 0.9934\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0269 - accuracy: 0.9934\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0265 - accuracy: 0.9934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18eb132ec40>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,y_train,batch_size=32,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec799d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred_test > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a7adb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is:  97.37 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[65,  2],\n",
       "       [ 1, 46]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(y_test,y_pred)\n",
    "print(\"Test accuracy is: \",round(test_accuracy*100,2),'%')\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dac45ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, f1_score, recall_score\n",
    "precision = precision_score(y_test,y_pred)\n",
    "recall = recall_score(y_test,y_pred)\n",
    "f1 = f1_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c622ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 95.83 %\n",
      "Recall: 97.87 %\n",
      "F1 Score: 96.84 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision:\",round(precision*100,2),\"%\")\n",
    "print(\"Recall:\",round(recall*100,2),\"%\")\n",
    "print(\"F1 Score:\",round(f1*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ebee183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True negatives:  65 \n",
      "False positives:  2 \n",
      "False negatives:  1 \n",
      "True positives:  46\n"
     ]
    }
   ],
   "source": [
    "# Let's see the confusion metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
    "\n",
    "print('True negatives: ', tn, '\\nFalse positives: ', fp, '\\nFalse negatives: ', fn, '\\nTrue positives: ', tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3ec819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validate the model\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "def built_classifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units=9,kernel_initializer='he_uniform',activation='relu',input_dim=30))\n",
    "    classifier.add(Dense(units=9,kernel_initializer='glorot_uniform',activation='relu'))\n",
    "    classifier.add(Dense(units=1,kernel_initializer='glorot_uniform',activation='sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return classifier\n",
    "\n",
    "classifier = KerasClassifier(build_fn = built_classifier, batch_size = 32, epochs=100)\n",
    "accuracies = cross_val_score(estimator = classifier, X=X_train, y=y_train, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2b66794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97802198, 0.97802198, 0.94505495, 1.        , 0.97802198])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2456d702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9758241772651672"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = accuracies.mean()\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3749efa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 4s 126ms/step - loss: 0.5988 - accuracy: 0.7846 - val_loss: 0.5511 - val_accuracy: 0.8509\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.5286 - accuracy: 0.8725 - val_loss: 0.4878 - val_accuracy: 0.9035\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.4680 - accuracy: 0.9077 - val_loss: 0.4323 - val_accuracy: 0.9123\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.4141 - accuracy: 0.9341 - val_loss: 0.3804 - val_accuracy: 0.9035\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3635 - accuracy: 0.9407 - val_loss: 0.3352 - val_accuracy: 0.9035\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.3176 - accuracy: 0.9473 - val_loss: 0.2965 - val_accuracy: 0.9035\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.2768 - accuracy: 0.9516 - val_loss: 0.2619 - val_accuracy: 0.9123\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.2413 - accuracy: 0.9604 - val_loss: 0.2347 - val_accuracy: 0.9211\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.2117 - accuracy: 0.9604 - val_loss: 0.2122 - val_accuracy: 0.9211\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.1878 - accuracy: 0.9604 - val_loss: 0.1940 - val_accuracy: 0.9211\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.1685 - accuracy: 0.9626 - val_loss: 0.1806 - val_accuracy: 0.9211\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.1541 - accuracy: 0.9670 - val_loss: 0.1720 - val_accuracy: 0.9211\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.1424 - accuracy: 0.9714 - val_loss: 0.1635 - val_accuracy: 0.9298\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.1321 - accuracy: 0.9736 - val_loss: 0.1565 - val_accuracy: 0.9298\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.1237 - accuracy: 0.9736 - val_loss: 0.1510 - val_accuracy: 0.9298\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.1169 - accuracy: 0.9736 - val_loss: 0.1456 - val_accuracy: 0.9386\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.1106 - accuracy: 0.9736 - val_loss: 0.1410 - val_accuracy: 0.9386\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.1051 - accuracy: 0.9736 - val_loss: 0.1377 - val_accuracy: 0.9386\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.1005 - accuracy: 0.9780 - val_loss: 0.1341 - val_accuracy: 0.9386\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0960 - accuracy: 0.9780 - val_loss: 0.1302 - val_accuracy: 0.9386\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0922 - accuracy: 0.9780 - val_loss: 0.1274 - val_accuracy: 0.9386\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0885 - accuracy: 0.9780 - val_loss: 0.1251 - val_accuracy: 0.9386\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0856 - accuracy: 0.9780 - val_loss: 0.1226 - val_accuracy: 0.9386\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0827 - accuracy: 0.9780 - val_loss: 0.1207 - val_accuracy: 0.9386\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0798 - accuracy: 0.9780 - val_loss: 0.1193 - val_accuracy: 0.9386\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0773 - accuracy: 0.9824 - val_loss: 0.1174 - val_accuracy: 0.9386\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0750 - accuracy: 0.9846 - val_loss: 0.1154 - val_accuracy: 0.9386\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0733 - accuracy: 0.9846 - val_loss: 0.1141 - val_accuracy: 0.9386\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0712 - accuracy: 0.9846 - val_loss: 0.1134 - val_accuracy: 0.9386\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0700 - accuracy: 0.9846 - val_loss: 0.1124 - val_accuracy: 0.9386\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0684 - accuracy: 0.9846 - val_loss: 0.1110 - val_accuracy: 0.9386\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0669 - accuracy: 0.9846 - val_loss: 0.1090 - val_accuracy: 0.9386\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0655 - accuracy: 0.9846 - val_loss: 0.1081 - val_accuracy: 0.9386\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0644 - accuracy: 0.9846 - val_loss: 0.1065 - val_accuracy: 0.9386\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0632 - accuracy: 0.9846 - val_loss: 0.1061 - val_accuracy: 0.9386\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0621 - accuracy: 0.9846 - val_loss: 0.1056 - val_accuracy: 0.9386\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0612 - accuracy: 0.9846 - val_loss: 0.1059 - val_accuracy: 0.9386\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 22ms/step - loss: 0.0604 - accuracy: 0.9868 - val_loss: 0.1044 - val_accuracy: 0.9386\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0596 - accuracy: 0.9868 - val_loss: 0.1038 - val_accuracy: 0.9386\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0586 - accuracy: 0.9868 - val_loss: 0.1030 - val_accuracy: 0.9386\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0576 - accuracy: 0.9868 - val_loss: 0.1027 - val_accuracy: 0.9386\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0569 - accuracy: 0.9868 - val_loss: 0.1021 - val_accuracy: 0.9386\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0562 - accuracy: 0.9890 - val_loss: 0.1016 - val_accuracy: 0.9386\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0553 - accuracy: 0.9890 - val_loss: 0.1015 - val_accuracy: 0.9386\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0546 - accuracy: 0.9890 - val_loss: 0.1013 - val_accuracy: 0.9386\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0536 - accuracy: 0.9890 - val_loss: 0.1009 - val_accuracy: 0.9386\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0535 - accuracy: 0.9890 - val_loss: 0.1017 - val_accuracy: 0.9386\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0526 - accuracy: 0.9890 - val_loss: 0.1006 - val_accuracy: 0.9386\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0519 - accuracy: 0.9890 - val_loss: 0.1002 - val_accuracy: 0.9386\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0511 - accuracy: 0.9890 - val_loss: 0.0990 - val_accuracy: 0.9386\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0507 - accuracy: 0.9890 - val_loss: 0.0959 - val_accuracy: 0.9386\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0500 - accuracy: 0.9890 - val_loss: 0.0948 - val_accuracy: 0.9386\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0495 - accuracy: 0.9890 - val_loss: 0.0941 - val_accuracy: 0.9386\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0489 - accuracy: 0.9890 - val_loss: 0.0943 - val_accuracy: 0.9386\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0483 - accuracy: 0.9890 - val_loss: 0.0939 - val_accuracy: 0.9386\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0477 - accuracy: 0.9890 - val_loss: 0.0935 - val_accuracy: 0.9386\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0471 - accuracy: 0.9890 - val_loss: 0.0930 - val_accuracy: 0.9386\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0467 - accuracy: 0.9890 - val_loss: 0.0931 - val_accuracy: 0.9386\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0460 - accuracy: 0.9890 - val_loss: 0.0922 - val_accuracy: 0.9386\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0454 - accuracy: 0.9890 - val_loss: 0.0910 - val_accuracy: 0.9474\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0451 - accuracy: 0.9868 - val_loss: 0.0900 - val_accuracy: 0.9474\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0448 - accuracy: 0.9868 - val_loss: 0.0891 - val_accuracy: 0.9474\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0440 - accuracy: 0.9868 - val_loss: 0.0879 - val_accuracy: 0.9474\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0434 - accuracy: 0.9868 - val_loss: 0.0870 - val_accuracy: 0.9474\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0430 - accuracy: 0.9912 - val_loss: 0.0867 - val_accuracy: 0.9474\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0425 - accuracy: 0.9912 - val_loss: 0.0864 - val_accuracy: 0.9474\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0421 - accuracy: 0.9912 - val_loss: 0.0861 - val_accuracy: 0.9561\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0416 - accuracy: 0.9912 - val_loss: 0.0857 - val_accuracy: 0.9561\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0413 - accuracy: 0.9912 - val_loss: 0.0847 - val_accuracy: 0.9561\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0408 - accuracy: 0.9912 - val_loss: 0.0847 - val_accuracy: 0.9561\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0404 - accuracy: 0.9912 - val_loss: 0.0844 - val_accuracy: 0.9561\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0400 - accuracy: 0.9912 - val_loss: 0.0836 - val_accuracy: 0.9561\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0395 - accuracy: 0.9912 - val_loss: 0.0830 - val_accuracy: 0.9561\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0392 - accuracy: 0.9912 - val_loss: 0.0822 - val_accuracy: 0.9561\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0392 - accuracy: 0.9912 - val_loss: 0.0818 - val_accuracy: 0.9649\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0385 - accuracy: 0.9912 - val_loss: 0.0814 - val_accuracy: 0.9561\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0381 - accuracy: 0.9912 - val_loss: 0.0813 - val_accuracy: 0.9649\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0376 - accuracy: 0.9912 - val_loss: 0.0809 - val_accuracy: 0.9561\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0372 - accuracy: 0.9912 - val_loss: 0.0804 - val_accuracy: 0.9561\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0369 - accuracy: 0.9912 - val_loss: 0.0798 - val_accuracy: 0.9561\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0366 - accuracy: 0.9912 - val_loss: 0.0802 - val_accuracy: 0.9561\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0362 - accuracy: 0.9912 - val_loss: 0.0806 - val_accuracy: 0.9649\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0357 - accuracy: 0.9912 - val_loss: 0.0810 - val_accuracy: 0.9649\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0355 - accuracy: 0.9912 - val_loss: 0.0806 - val_accuracy: 0.9649\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0351 - accuracy: 0.9912 - val_loss: 0.0803 - val_accuracy: 0.9649\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0348 - accuracy: 0.9912 - val_loss: 0.0798 - val_accuracy: 0.9649\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0347 - accuracy: 0.9912 - val_loss: 0.0800 - val_accuracy: 0.9649\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0341 - accuracy: 0.9912 - val_loss: 0.0793 - val_accuracy: 0.9649\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0338 - accuracy: 0.9912 - val_loss: 0.0789 - val_accuracy: 0.9649\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0333 - accuracy: 0.9912 - val_loss: 0.0797 - val_accuracy: 0.9649\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 0.0330 - accuracy: 0.9912 - val_loss: 0.0797 - val_accuracy: 0.9649\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0327 - accuracy: 0.9912 - val_loss: 0.0799 - val_accuracy: 0.9649\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0324 - accuracy: 0.9912 - val_loss: 0.0797 - val_accuracy: 0.9649\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.0321 - accuracy: 0.9912 - val_loss: 0.0796 - val_accuracy: 0.9649\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0319 - accuracy: 0.9912 - val_loss: 0.0803 - val_accuracy: 0.9649\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0315 - accuracy: 0.9912 - val_loss: 0.0798 - val_accuracy: 0.9649\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0311 - accuracy: 0.9912 - val_loss: 0.0794 - val_accuracy: 0.9649\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0308 - accuracy: 0.9912 - val_loss: 0.0804 - val_accuracy: 0.9649\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0305 - accuracy: 0.9912 - val_loss: 0.0799 - val_accuracy: 0.9649\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0302 - accuracy: 0.9912 - val_loss: 0.0802 - val_accuracy: 0.9649\n"
     ]
    }
   ],
   "source": [
    "history = classifier.fit(X_train,y_train,batch_size =32, epochs = 100, validation_data = (X_test,y_test))\n",
    "history_dict =history.history\n",
    "loss_values =history_dict['loss']\n",
    "val_loss_values =history_dict['val_loss']\n",
    "epochs =range(1,len(loss_values)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc534363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs,loss_values,'ro',label='Training Loss')\n",
    "plt.plot (epochs,val_loss_values,'b',label ='Validation Loss')\n",
    "plt.title ('Training & validation_data')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1b1511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37d833e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7214d70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e07a137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d864efa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
